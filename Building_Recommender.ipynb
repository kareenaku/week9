{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ucMoPnB0RIcM"
      },
      "outputs": [],
      "source": [
        "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "datasets_path = 'datasets'\n",
        "if not os.path.exists(datasets_path):\n",
        "    os.makedirs(datasets_path)\n",
        "\n",
        "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')\n",
        "     "
      ],
      "metadata": {
        "id": "VnaT9vNsT87O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "\n",
        "small_f = urllib.urlretrieve (small_dataset_url, small_dataset_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "RsffiV2aUfWv",
        "outputId": "7035e612-3398-42ff-ee37-b6c89d985da1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2c6b54150a10>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msmall_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msmall_dataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'urlretrieve'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "small_f = urllib.request.urlretrieve(small_dataset_url, small_dataset_path)"
      ],
      "metadata": {
        "id": "i1H14AGEpjI2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
        "    z.extractall(datasets_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "RFlx_tItlkxt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext(\"local[*]\", \"MovieRecommendation\")\n",
        "\n",
        "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
        "\n",
        "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
        "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEQD50kvlrxu",
        "outputId": "bb16d931-dc78-40c7-8455-4e0a0025b633"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=089d375fe4feb5ab183b95e2d6fb79c057ebd3ef4e70977c32d9dd74045494a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
      ],
      "metadata": {
        "id": "ycyWKuxgmsaN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_ratings_data.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWq2J4Bvmw0x",
        "outputId": "135da7fb-be10-45d7-d0b2-89ff7d5ed777"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
        "\n",
        "small_movies_raw_data = sc.textFile(small_movies_file)\n",
        "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
        "\n",
        "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
        "    \n",
        "small_movies_data.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPZwGpDXnCpI",
        "outputId": "7d427aa5-9c1c-463c-8abb-be8ead777b42"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'Toy Story (1995)'),\n",
              " ('2', 'Jumanji (1995)'),\n",
              " ('3', 'Grumpier Old Men (1995)')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql import Row"
      ],
      "metadata": {
        "id": "eQ6EkvIIpbvx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and parse the data\n",
        "data = sc.textFile(small_ratings_file)\n",
        "header = data.first()\n",
        "data = data.filter(lambda row: row != header)\n",
        "ratings = data.map(lambda l: l.split(',')).map(lambda l: Row(userId=int(l[0]), movieId=int(l[1]), rating=float(l[2]), timestamp=int(l[3])))\n",
        "ratings_df = spark.createDataFrame(ratings)"
      ],
      "metadata": {
        "id": "ddVoNoSmpdYt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "small_ratings_file = \"datasets/ml-latest-small/ratings.csv\"\n",
        "if os.path.exists(small_ratings_file):\n",
        "    print(\"File exists\")\n",
        "else:\n",
        "    print(\"File does not exist\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl7dEQ3ssD-i",
        "outputId": "0c4b366d-8b1c-4569-c568-4c2e8c7689c6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters\n",
        "ranks = [5, 10, 20]\n",
        "lambdas = [0.01]\n",
        "num_iterations = [10]"
      ],
      "metadata": {
        "id": "bB8MNaEaqM7j"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the hyperparameters\n",
        "for rank in ranks:\n",
        "  for lambda_val in lambdas:\n",
        "    for num_iter in num_iterations:\n",
        "      \n",
        "# Build the recommendation model using ALS on the training data\n",
        "      als = ALS(maxIter=num_iter, regParam=lambda_val, rank=rank, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "      model = als.fit(ratings_df)"
      ],
      "metadata": {
        "id": "MAwQMcSlqRGc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "id": "LFYOQB9It6ZK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"Rank: \", rank, \", lambda: \", lambda_val, \", numIter: \", num_iter, \", RMSE: \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luz9JYeuqpTS",
        "outputId": "52cc55c7-706a-4f7b-ee78-1e80968431d1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank:  20 , lambda:  0.01 , numIter:  10 , RMSE:  0.3603422364405746\n"
          ]
        }
      ]
    }
  ]
}